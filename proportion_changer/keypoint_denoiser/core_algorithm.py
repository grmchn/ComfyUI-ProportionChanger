"""
Core Algorithm Implementation
ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ™ãƒ¼ã‚¹7æ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ¡ã‚¤ãƒ³å®Ÿè£…
"""

import numpy as np
import copy
import time
from typing import List, Dict, Tuple, Optional, Any

try:
    from .config import DenoiserConfig
    from .kalman_filter import KeypointKalmanFilter, initialize_kalman_filters, update_kalman_filters_batch
    from .body_analysis import analyze_body_statistics_enhanced, extract_pose_keypoints_from_frame, calculate_enhanced_orientation_score, get_frame_pose_data
except ImportError:
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ãƒ†ã‚¹ãƒˆç”¨
    from config import DenoiserConfig
    from kalman_filter import KeypointKalmanFilter, initialize_kalman_filters, update_kalman_filters_batch
    from body_analysis import analyze_body_statistics_enhanced, extract_pose_keypoints_from_frame, calculate_enhanced_orientation_score, get_frame_pose_data

def log_phase_start(phase_num: int, phase_name: str, verbose: bool = True):
    """æ®µéšé–‹å§‹ãƒ­ã‚°"""
    if verbose:
        print(f"\nğŸ”¥ [Phase {phase_num}] {phase_name} é–‹å§‹...")

def log_phase_end(phase_num: int, phase_name: str, elapsed_ms: float, verbose: bool = True):
    """æ®µéšçµ‚äº†ãƒ­ã‚°"""
    if verbose:
        print(f"âœ… [Phase {phase_num}] {phase_name} å®Œäº† ({elapsed_ms:.1f}ms)")

def preprocess_keypoints(pose_keypoint_batch: List, config: DenoiserConfig) -> List:
    """
    Phase 1: å‰å‡¦ç†ï¼ˆæ­£è¦åŒ–ãƒ»ä¿¡é ¼åº¦ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ»è»½ã„æ¬ æåŸ‹ã‚ï¼‰
    """
    start_time = time.time()
    log_phase_start(1, "å‰å‡¦ç†ãƒ»ä¿¡é ¼åº¦ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", config.verbose_logging)
    
    if config.verbose_logging:
        print(f"  ğŸ“¥ å…¥åŠ›ãƒãƒƒãƒã‚µã‚¤ã‚º: {len(pose_keypoint_batch)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
    
    # ç¾æ™‚ç‚¹ã§ã¯åŸºæœ¬çš„ãªã‚³ãƒ”ãƒ¼ã®ã¿ï¼ˆå°†æ¥çš„ã«æ‹¡å¼µäºˆå®šï¼‰
    preprocessed = copy.deepcopy(pose_keypoint_batch)
    
    # ä¿¡é ¼åº¦çµ±è¨ˆ
    if config.verbose_logging:
        total_keypoints = 0
        low_confidence_count = 0
        
        for frame_data in preprocessed:
            people_data = get_frame_pose_data(frame_data)
            if people_data:
                keypoints = extract_pose_keypoints_from_frame(people_data)
                for kp in keypoints:
                    total_keypoints += 1
                    if kp[2] < config.conf_min:
                        low_confidence_count += 1
        
        low_conf_rate = low_confidence_count / max(total_keypoints, 1)
        print(f"  ğŸ“Š ä½ä¿¡é ¼åº¦ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆç‡: {low_conf_rate:.1%} (é–¾å€¤<{config.conf_min})")
    
    elapsed_ms = (time.time() - start_time) * 1000
    log_phase_end(1, "å‰å‡¦ç†", elapsed_ms, config.verbose_logging)
    
    return preprocessed

def apply_kalman_filtering(pose_keypoint_batch: List, body_stats: Dict, config: DenoiserConfig) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Phase 3-4: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ + ã‚«ã‚¤äºŒä¹—ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    """
    start_time = time.time()
    log_phase_start(3, "ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†ãƒ»å¤–ã‚Œå€¤ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", config.verbose_logging)
    
    T = len(pose_keypoint_batch)
    J = 25  # DWPose body keypoints
    
    # çµæœä¿å­˜ç”¨é…åˆ—
    filtered_positions = np.zeros((T, J, 2), dtype=np.float32)
    filtered_confidences = np.zeros((T, J), dtype=np.float32)
    gate_results = np.zeros((T, J), dtype=bool)  # ã‚²ãƒ¼ãƒˆé€šéçµæœ
    
    # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿åˆæœŸåŒ–
    if config.verbose_logging:
        print("  ğŸ”® ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿åˆæœŸåŒ–...")
    
    first_frame_people = get_frame_pose_data(pose_keypoint_batch[0])
    first_valid_frame = extract_pose_keypoints_from_frame(first_frame_people)
    kalman_filters = initialize_kalman_filters(first_valid_frame, body_stats['primary_scale'], config)
    
    if config.verbose_logging:
        print(f"  ğŸ”® åˆæœŸåŒ–å®Œäº†: {len(kalman_filters)}å€‹ã®ãƒ•ã‚£ãƒ«ã‚¿")
    
    # é€²æ—è¡¨ç¤ºç”¨
    progress_step = max(1, T // 10)
    total_observations = 0
    total_accepted = 0
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ«ãƒ¼ãƒ—å‡¦ç†
    for frame_idx in range(T):
        current_frame_data = get_frame_pose_data(pose_keypoint_batch[frame_idx])
        current_keypoints = extract_pose_keypoints_from_frame(current_frame_data)
        
        # ç¾åœ¨ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ­£é¢åº¦è¨ˆç®—
        orientation_score = calculate_enhanced_orientation_score(current_keypoints)
        
        # ãƒ€ãƒ³ã‚¹å‹•ä½œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆPhase 4ã§æœ¬æ ¼å®Ÿè£…äºˆå®šï¼‰
        protection_factors = {}  # ç¾åœ¨ã¯ç©ºè¾æ›¸
        
        # ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒãƒƒãƒæ›´æ–°
        positions, acceptances, mahalanobis_distances = update_kalman_filters_batch(
            kalman_filters, current_keypoints, orientation_score, protection_factors
        )
        
        # çµæœã‚’é…åˆ—ã«ä¿å­˜
        for kp_idx in range(J):
            if kp_idx in positions:
                filtered_positions[frame_idx, kp_idx] = positions[kp_idx]
                filtered_confidences[frame_idx, kp_idx] = current_keypoints[kp_idx][2] if acceptances[kp_idx] else current_keypoints[kp_idx][2] * 0.7
                gate_results[frame_idx, kp_idx] = acceptances[kp_idx]
                
                total_observations += 1
                if acceptances[kp_idx]:
                    total_accepted += 1
            else:
                # ãƒ•ã‚£ãƒ«ã‚¿æœªåˆæœŸåŒ–ï¼šä½ä¿¡é ¼åº¦ã¨ã—ã¦è¨˜éŒ²
                filtered_positions[frame_idx, kp_idx] = current_keypoints[kp_idx][:2]
                filtered_confidences[frame_idx, kp_idx] = 0.1
                gate_results[frame_idx, kp_idx] = False
        
        # é€²æ—è¡¨ç¤º
        if config.verbose_logging and frame_idx % progress_step == 0:
            progress = (frame_idx + 1) / T
            print(f"  âš¡ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†é€²æ—: {progress:.0%} ({frame_idx+1}/{T})")
    
    # çµ±è¨ˆæƒ…å ±
    acceptance_rate = total_accepted / max(total_observations, 1)
    
    if config.verbose_logging:
        print(f"  ğŸ“Š è¦³æ¸¬å—ã‘å…¥ã‚Œç‡: {acceptance_rate:.1%}")
        print(f"  ğŸ“Š ç·è¦³æ¸¬æ•°: {total_observations}, å—ã‘å…¥ã‚Œæ•°: {total_accepted}")
    
    elapsed_ms = (time.time() - start_time) * 1000
    log_phase_end(3, "ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†", elapsed_ms, config.verbose_logging)
    
    return filtered_positions, filtered_confidences, gate_results

def apply_structural_constraints(filtered_positions: np.ndarray, 
                                filtered_confidences: np.ndarray,
                                body_stats: Dict, 
                                config: DenoiserConfig) -> np.ndarray:
    """
    Phase 5: æ§‹é€ æŠ•å½±ï¼ˆéª¨é•·åˆ¶ç´„ã®è»½é‡å®Ÿè£…ï¼‰
    """
    start_time = time.time()
    log_phase_start(5, "æ§‹é€ æŠ•å½±ãƒ»éª¨é•·åˆ¶ç´„", config.verbose_logging)
    
    if not config.enable_bone_constraints:
        if config.verbose_logging:
            print("  â­ï¸ æ§‹é€ æŠ•å½±ç„¡åŠ¹åŒ–: ã‚¹ã‚­ãƒƒãƒ—")
        log_phase_end(5, "æ§‹é€ æŠ•å½±ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰", 0, config.verbose_logging)
        return filtered_positions.copy()
    
    T, J = filtered_positions.shape[:2]
    adjusted_positions = filtered_positions.copy()
    
    # ç°¡å˜ãªçµ±è¨ˆ
    total_adjustments = 0
    frames_processed = 0
    
    if config.verbose_logging:
        print(f"  ğŸ¦´ æŠ•å½±é–“éš”: {config.projection_interval}ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨")
        print(f"  ğŸ¦´ æœ€å¤§åå¾©æ•°: {config.max_iterations}")
    
    # æŠ•å½±é–“éš”ã«å¾“ã£ã¦å‡¦ç†
    for frame_idx in range(0, T, config.projection_interval):
        # ç°¡å˜ãªéª¨é•·ãƒã‚§ãƒƒã‚¯ï¼ˆå®Ÿè£…ã¯ç°¡ç•¥åŒ–ï¼‰
        frame_keypoints = adjusted_positions[frame_idx]
        
        # ä¸»è¦ãªéª¨é•·ã‚’ãƒã‚§ãƒƒã‚¯
        adjustments_made = 0
        
        # ä¸Šè…•é•·ã®ãƒã‚§ãƒƒã‚¯ï¼ˆå³è…•ï¼‰
        if (filtered_confidences[frame_idx, 2] > 0.3 and 
            filtered_confidences[frame_idx, 3] > 0.3):
            
            shoulder_pos = frame_keypoints[2]  # å³è‚©
            elbow_pos = frame_keypoints[3]    # å³è‚˜
            current_length = np.linalg.norm(elbow_pos - shoulder_pos)
            
            # çµ±è¨ˆçš„åŸºæº–ã¨æ¯”è¼ƒï¼ˆç°¡ç•¥åŒ–ï¼‰
            if 'upper_arm_r' in body_stats['joint_references']:
                ref_length = body_stats['joint_references']['upper_arm_r']['median']
                
                # è¨±å®¹ç¯„å›²ãƒã‚§ãƒƒã‚¯
                min_length = ref_length * 0.6
                max_length = ref_length * 1.4
                
                if current_length < min_length or current_length > max_length:
                    # è»½ã„èª¿æ•´
                    target_length = np.clip(current_length, min_length, max_length)
                    direction = (elbow_pos - shoulder_pos) / (current_length + 1e-8)
                    
                    adjusted_elbow = shoulder_pos + direction * target_length
                    adjusted_positions[frame_idx, 3] = adjusted_elbow
                    
                    adjustments_made += 1
                    total_adjustments += 1
        
        frames_processed += 1
        
        # é€²æ—è¡¨ç¤º
        if config.verbose_logging and frame_idx % (config.projection_interval * 10) == 0:
            progress = frame_idx / T
            print(f"  ğŸ¦´ æŠ•å½±é€²æ—: {progress:.0%}")
    
    if config.verbose_logging:
        avg_adjustments = total_adjustments / max(frames_processed, 1)
        print(f"  ğŸ“Š å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frames_processed}")
        print(f"  ğŸ“Š ç·èª¿æ•´å›æ•°: {total_adjustments}")
        print(f"  ğŸ“Š å¹³å‡èª¿æ•´æ•°/ãƒ•ãƒ¬ãƒ¼ãƒ : {avg_adjustments:.2f}")
    
    elapsed_ms = (time.time() - start_time) * 1000
    log_phase_end(5, "æ§‹é€ æŠ•å½±", elapsed_ms, config.verbose_logging)
    
    return adjusted_positions

def apply_post_smoothing(filtered_positions: np.ndarray,
                        filtered_confidences: np.ndarray,
                        config: DenoiserConfig) -> np.ndarray:
    """
    Phase 6: å¾Œå‡¦ç†ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
    """
    start_time = time.time()
    log_phase_start(6, "å¾Œå‡¦ç†ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°", config.verbose_logging)
    
    T, J = filtered_positions.shape[:2]
    smoothed_positions = filtered_positions.copy()
    
    if config.use_rts_smoother:
        if config.verbose_logging:
            print("  ğŸ¢ RTSã‚¹ãƒ ãƒ¼ã‚¶é©ç”¨ï¼ˆç°¡ç•¥å®Ÿè£…ï¼‰...")
        # RTSã‚¹ãƒ ãƒ¼ã‚¶ã®ç°¡ç•¥å®Ÿè£…ï¼ˆå°†æ¥çš„ã«æ‹¡å¼µï¼‰
        # ç¾åœ¨ã¯è»½ã„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã§ä»£ç”¨
        
    else:
        if config.verbose_logging:
            print("  ğŸ¢ è»½é‡ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨...")
    
    # æœ«ç«¯ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆé¡”ãƒ»æ‰‹é¦–ãƒ»è¶³é¦–ï¼‰ã«è»½ã„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
    try:
        from .config import FACE_KEYPOINT_INDICES, EXTREMITY_INDICES
    except ImportError:
        from config import FACE_KEYPOINT_INDICES, EXTREMITY_INDICES
    target_indices = FACE_KEYPOINT_INDICES + EXTREMITY_INDICES
    
    half_window = config.light_window_size // 2
    smoothing_applied = 0
    
    for kp_idx in target_indices:
        for t in range(half_window, T - half_window):
            if filtered_confidences[t, kp_idx] > 0.3:  # ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯
                # è¿‘å‚ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®é‡ã¿ä»˜ãå¹³å‡
                window_positions = filtered_positions[t-half_window:t+half_window+1, kp_idx]
                window_confs = filtered_confidences[t-half_window:t+half_window+1, kp_idx]
                
                # ä¿¡é ¼åº¦é‡ã¿ä»˜ãå¹³å‡
                valid_mask = window_confs > 0.3
                if np.sum(valid_mask) >= 3:  # æœ€å°æœ‰åŠ¹ç‚¹æ•°
                    weights = window_confs[valid_mask]
                    smoothed_positions[t, kp_idx] = np.average(window_positions[valid_mask], 
                                                             axis=0, weights=weights)
                    smoothing_applied += 1
    
    if config.verbose_logging:
        print(f"  ğŸ“Š ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨ç®‡æ‰€: {smoothing_applied}")
        print(f"  ğŸ“Š å¯¾è±¡ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {len(target_indices)}å€‹")
    
    elapsed_ms = (time.time() - start_time) * 1000
    log_phase_end(6, "å¾Œå‡¦ç†ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°", elapsed_ms, config.verbose_logging)
    
    return smoothed_positions

def apply_gap_interpolation(smoothed_positions: np.ndarray,
                           filtered_confidences: np.ndarray,
                           config: DenoiserConfig) -> np.ndarray:
    """
    Phase 7: ã‚®ãƒ£ãƒƒãƒ—è£œé–“
    """
    start_time = time.time()
    log_phase_start(7, "ã‚®ãƒ£ãƒƒãƒ—è£œé–“ãƒ»æœ€çµ‚ä»•ä¸Šã’", config.verbose_logging)
    
    T, J = smoothed_positions.shape[:2]
    final_positions = smoothed_positions.copy()
    
    gaps_found = 0
    gaps_interpolated = 0
    
    for kp_idx in range(J):
        # ä½ä¿¡é ¼åº¦åŒºé–“ã‚’ç‰¹å®š
        missing_mask = filtered_confidences[:, kp_idx] < config.conf_min
        
        if not np.any(missing_mask):
            continue  # ã‚®ãƒ£ãƒƒãƒ—ãªã—
        
        # é€£ç¶šæ¬ æåŒºé–“ã‚’ç‰¹å®š
        gaps = identify_gaps(missing_mask)
        gaps_found += len(gaps)
        
        for gap_start, gap_end in gaps:
            gap_length = gap_end - gap_start + 1
            
            if gap_length <= config.short_gap_threshold:
                # çŸ­ã‚®ãƒ£ãƒƒãƒ—ï¼šç·šå½¢è£œé–“
                interpolated = linear_interpolate_gap(
                    smoothed_positions, kp_idx, gap_start, gap_end
                )
                final_positions[gap_start:gap_end+1, kp_idx] = interpolated
                gaps_interpolated += 1
                
            elif gap_length <= config.medium_gap_threshold:
                # ä¸­ã‚®ãƒ£ãƒƒãƒ—ï¼šã‚¹ãƒ—ãƒ©ã‚¤ãƒ³è£œé–“ï¼ˆç°¡ç•¥å®Ÿè£…ï¼‰
                interpolated = linear_interpolate_gap(  # ç¾åœ¨ã¯ç·šå½¢ã§ä»£ç”¨
                    smoothed_positions, kp_idx, gap_start, gap_end
                )
                final_positions[gap_start:gap_end+1, kp_idx] = interpolated
                gaps_interpolated += 1
                
            # é•·ã‚®ãƒ£ãƒƒãƒ—ã¯ç¾åœ¨ã®å€¤ã‚’ä¿æŒï¼ˆè£œé–“ã—ãªã„ï¼‰
    
    if config.verbose_logging:
        print(f"  ğŸ“Š æ¤œå‡ºã‚®ãƒ£ãƒƒãƒ—æ•°: {gaps_found}")
        print(f"  ğŸ“Š è£œé–“æ¸ˆã¿ã‚®ãƒ£ãƒƒãƒ—æ•°: {gaps_interpolated}")
    
    elapsed_ms = (time.time() - start_time) * 1000
    log_phase_end(7, "ã‚®ãƒ£ãƒƒãƒ—è£œé–“", elapsed_ms, config.verbose_logging)
    
    return final_positions

def identify_gaps(missing_mask: np.ndarray) -> List[Tuple[int, int]]:
    """é€£ç¶šã™ã‚‹æ¬ æåŒºé–“ã‚’ç‰¹å®š"""
    gaps = []
    in_gap = False
    gap_start = 0
    
    for i, is_missing in enumerate(missing_mask):
        if is_missing and not in_gap:
            gap_start = i
            in_gap = True
        elif not is_missing and in_gap:
            gaps.append((gap_start, i-1))
            in_gap = False
    
    # æœ€å¾Œã¾ã§ã‚®ãƒ£ãƒƒãƒ—ãŒç¶šãå ´åˆ
    if in_gap:
        gaps.append((gap_start, len(missing_mask)-1))
    
    return gaps

def linear_interpolate_gap(positions: np.ndarray, kp_idx: int, start: int, end: int) -> np.ndarray:
    """ç·šå½¢è£œé–“"""
    T = positions.shape[0]
    
    # å‰å¾Œã®æœ‰åŠ¹ãªç‚¹ã‚’å–å¾—
    before_pos = positions[start-1, kp_idx] if start > 0 else positions[end+1, kp_idx]
    after_pos = positions[end+1, kp_idx] if end < T-1 else positions[start-1, kp_idx]
    
    # ç·šå½¢è£œé–“
    gap_length = end - start + 1
    interpolated = np.zeros((gap_length, 2))
    
    for i in range(gap_length):
        t = (i + 1) / (gap_length + 1)  # 0 < t < 1
        interpolated[i] = (1 - t) * before_pos + t * after_pos
    
    return interpolated

def convert_to_pose_keypoint_batch(positions: np.ndarray, 
                                 confidences: np.ndarray, 
                                 original_batch: List) -> List:
    """NumPyé…åˆ—ã‹ã‚‰POSE_KEYPOINTå½¢å¼ã«å¤‰æ›"""
    result_batch = []
    
    for frame_idx in range(len(positions)):
        frame_data = copy.deepcopy(original_batch[frame_idx])
        people_data = get_frame_pose_data(frame_data)
        
        # pose_keypoints_2dã‚’æ›´æ–°
        new_pose_keypoints = []
        for kp_idx in range(25):
            x, y = positions[frame_idx, kp_idx]
            conf = confidences[frame_idx, kp_idx]
            new_pose_keypoints.extend([float(x), float(y), float(conf)])
        
        people_data['pose_keypoints_2d'] = new_pose_keypoints
        result_batch.append(frame_data)
    
    return result_batch

def denoise_pose_keypoints_kalman(pose_keypoint_batch: List,
                                 config: Optional[DenoiserConfig] = None) -> List:
    """
    ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ™ãƒ¼ã‚¹KeyPointãƒ‡ãƒã‚¤ã‚¶ãƒ¼ï¼ˆ7æ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œå…¨ç‰ˆï¼‰
    
    Args:
        pose_keypoint_batch: POSE_KEYPOINTå½¢å¼ã®ãƒãƒƒãƒ
        config: ãƒ‡ãƒã‚¤ã‚¶ãƒ¼è¨­å®šï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼‰
    
    Returns:
        List: ãƒã‚¤ã‚ºé™¤å»æ¸ˆã¿POSE_KEYPOINTãƒãƒƒãƒ
    """
    
    if config is None:
        config = DenoiserConfig()
    
    if len(pose_keypoint_batch) < 3:
        if config.verbose_logging:
            print("âš ï¸ ãƒãƒƒãƒã‚µã‚¤ã‚ºä¸è¶³ï¼ˆ<3ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰: å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—")
        return pose_keypoint_batch
    
    total_start_time = time.time()
    
    if config.verbose_logging:
        print(f"\n{'='*80}")
        print(f"ğŸš€ KeyPoint Denoiser å®Ÿè¡Œé–‹å§‹")
        print(f"{'='*80}")
        print(f"ğŸ“¥ å…¥åŠ›: {len(pose_keypoint_batch)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
        print(f"âš™ï¸ è¨­å®š: è©³ç´°ãƒ­ã‚°{'ON' if config.verbose_logging else 'OFF'}, éª¨é•·åˆ¶ç´„{'ON' if config.enable_bone_constraints else 'OFF'}")
    
    try:
        # Phase 1: å‰å‡¦ç†
        preprocessed_batch = preprocess_keypoints(pose_keypoint_batch, config)
        
        # Phase 2: ä½“ã‚¹ã‚±ãƒ¼ãƒ«ãƒ»å‘ãæ¨å®šï¼ˆanalyze_body_statistics_enhancedå†…ã§Phase 1-2ã®ãƒ­ã‚°å‡ºåŠ›ï¼‰
        body_stats = analyze_body_statistics_enhanced(preprocessed_batch, config)
        
        # Phase 3-4: ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ + ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        filtered_positions, filtered_confidences, gate_results = apply_kalman_filtering(
            preprocessed_batch, body_stats, config
        )
        
        # Phase 5: æ§‹é€ æŠ•å½±
        adjusted_positions = apply_structural_constraints(
            filtered_positions, filtered_confidences, body_stats, config
        )
        
        # Phase 6: å¾Œå‡¦ç†ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
        smoothed_positions = apply_post_smoothing(
            adjusted_positions, filtered_confidences, config
        )
        
        # Phase 7: ã‚®ãƒ£ãƒƒãƒ—è£œé–“
        final_positions = apply_gap_interpolation(
            smoothed_positions, filtered_confidences, config
        )
        
        # æœ€çµ‚å¤‰æ›
        result_batch = convert_to_pose_keypoint_batch(
            final_positions, filtered_confidences, preprocessed_batch
        )
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        total_elapsed_ms = (time.time() - total_start_time) * 1000
        total_keypoints = len(pose_keypoint_batch) * 25
        gated_keypoints = np.sum(~gate_results) if gate_results.size > 0 else 0
        rejection_rate = gated_keypoints / max(total_keypoints, 1)
        
        if config.verbose_logging:
            print(f"\n{'='*80}")
            print(f"âœ¨ KeyPoint Denoiser å‡¦ç†å®Œäº†!")
            print(f"{'='*80}")
            print(f"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed_ms:.1f}ms")
            print(f"ğŸ“Š ã‚²ãƒ¼ãƒˆæ£„å´ç‡: {rejection_rate:.1%}")
            print(f"ğŸ“Š å“è³ªå‘ä¸Šæ¨å®š: {(1-rejection_rate)*body_stats['quality_score']:.1%}")
            print(f"ğŸ¯ ä½“ã‚¹ã‚±ãƒ¼ãƒ«: {body_stats['primary_scale']:.4f}")
            print(f"ğŸ¯ æ­£é¢å‘ãæ¯”ç‡: {body_stats['orientation_stats']['front_facing_ratio']:.2%}")
            print(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å“è³ª: {body_stats['quality_score']:.3f}")
            print(f"{'='*80}")
        
        return result_batch
        
    except Exception as e:
        if config.verbose_logging:
            print(f"\nğŸ’¥ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        return pose_keypoint_batch